{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c65f5c46-015e-4d29-80a4-ae4a0fabe334",
   "metadata": {},
   "source": [
    "# Importing And Merging Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55793e40-d8ef-4022-9c39-595491a7d910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "import numpy as np\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from pmdarima import auto_arima\n",
    "import itertools\n",
    "import statsmodels.api as sm\n",
    "from datetime import timedelta\n",
    "from  pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "from time import time\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72cd271a-0e18-40d8-9a8c-e2ff2620d7b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ProductA.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df1 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProductA.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,)\n\u001b[0;32m      2\u001b[0m df1\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ProductA.csv'"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(r\"ProductA.csv\",index_col=0,)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c08374-2083-4383-9055-84bfb07d2367",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(r\"ProductA_fb_impressions.csv\")\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121a5bd4-26b1-4658-a85e-a4674cfad4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_csv(r\"ProductA_google_clicks.csv\")\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ea65d4-865f-4bb7-8b49-7ef97a35b418",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(pd.merge(df1, df2, on='Day Index'), df3, on='Day Index')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3447cde-d5a0-4cc4-8ba1-76da59d5e5fb",
   "metadata": {},
   "source": [
    "# Graph Plottings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a577423e-9d0d-48a8-8976-7c9cfaa4c835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of DayIndex vs Quantity\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Line plot for Day Index and Quantity\n",
    "plt.plot(df['Day Index'],  df['Quantity'], marker='o',  linestyle='-', color='blue',  label='New_Quantity (Sales)' )\n",
    "plt.title('Day Index vs Quantity Sales', fontsize=16) \n",
    "plt.xlabel('Day Index', fontsize=14) \n",
    "plt.ylabel('Sales', fontsize=14) \n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f20bd2-7080-4925-8691-3f21239589f2",
   "metadata": {},
   "source": [
    " * Fluctuating Sales: The graph shows a clear pattern of fluctuating sales over time. There are periods of high sales followed by periods of low sales, with no consistent upward or downward trend. This suggests that factors other than time might be influencing sales.\n",
    " * No Clear Correlation: There appears to be no strong correlation between the DayIndex and sales. This indicates that the day of the week or the day of the month doesn't have a significant impact on sales. Other factors, such as promotions, seasonality, or external events, might be driving the sales fluctuations.\n",
    " * Potential Seasonality: While the graph doesn't clearly show seasonal patterns, it's possible that there are underlying seasonal variations in sales that are not immediately apparent. Further analysis, such as comparing sales data from different years or analyzing sales by month, could reveal potential seasonal trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f33d97-9931-4616-808d-3355f75fdbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for DayIndex vs Impressions\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df['Day Index'], df['Impressions'], marker='o', linestyle='-', color='green', label='Impressions')\n",
    "plt.title('DayIndex vs Impressions', fontsize=16)\n",
    "plt.xlabel('DayIndex', fontsize=14)\n",
    "plt.ylabel('Impressions', fontsize=14)\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2c1619-d916-4413-a066-1aca9e1e8fc0",
   "metadata": {},
   "source": [
    " * Fluctuating Impressions: The graph shows a clear pattern of fluctuating impressions over time. There are periods of high impressions followed by periods of low impressions, with no consistent upward or downward trend. This suggests that factors other than time might be influencing impressions.\n",
    " * No Clear Correlation: There appears to be no strong correlation between the DayIndex and impressions. This indicates that the day of the week or the day of the month doesn't have a significant impact on impressions. Other factors, such as promotions, seasonality, or external events, might be driving the fluctuations in impressions.\n",
    " * Potential Seasonality: While the graph doesn't clearly show seasonal patterns, it's possible that there are underlying seasonal variations in impressions that are not immediately apparent. Further analysis, such as comparing impressions data from different years or analyzing impressions by month, could reveal potential seasonal trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2848321f-fc78-4cda-a480-a33caaa84887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for DayIndex vs Clicks\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df['Day Index'], df['Clicks'], marker='o', linestyle='-', color='red', label='Clicks')\n",
    "plt.title('DayIndex vs Clicks', fontsize=16)\n",
    "plt.xlabel('DayIndex', fontsize=14)\n",
    "plt.ylabel('Clicks', fontsize=14)\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc05500-391f-4cf8-9b84-09b006f056e4",
   "metadata": {},
   "source": [
    " * Fluctuating Clicks: The graph shows a clear pattern of fluctuating clicks over time. There are periods of high clicks followed by periods of low clicks, with no consistent upward or downward trend. This suggests that factors other than time might be influencing clicks.\n",
    " * No Clear Correlation: There appears to be no strong correlation between the DayIndex and clicks. This indicates that the day of the week or the day of the month doesn't have a significant impact on clicks. Other factors, such as promotions, seasonality, or external events, might be driving the fluctuations in clicks.\n",
    " * Potential Seasonality: While the graph doesn't clearly show seasonal patterns, it's possible that there are underlying seasonal variations in clicks that are not immediately apparent. Further analysis, such as comparing clicks data from different years or analyzing clicks by month, could reveal potential seasonal trends."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236c112e-6927-45be-9da9-f89a9830b598",
   "metadata": {},
   "source": [
    "# Basic Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a234c474-b548-446f-9344-debe8516fde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bce01ad-b793-4c80-9db8-3d2ee87b9528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate rows \n",
    "duplicate_rows = df[df.duplicated()]\n",
    "print(\"Duplicate Rows:\")\n",
    "print(duplicate_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bd172c-a8a4-4c58-a1a7-196202bc46f8",
   "metadata": {},
   "source": [
    "# Missing Value Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e3d24a-5d7e-4333-b4ab-237380975412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in the DataFrame\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing Values:\")\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0d57bc-d112-4c04-94de-b7432b52ec74",
   "metadata": {},
   "source": [
    "# Outlier Detection And Manupulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabf0f4b-886c-4692-b7cc-050aef05a08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "fig.subplots_adjust(wspace=0.5)\n",
    "\n",
    "# Box plot for metric 1\n",
    "sns.boxplot(data=df1, ax=axes[0], color='red') \n",
    "axes[0].set_title('Metric 1 Boxplot')\n",
    "\n",
    "# Box plot for metric 2\n",
    "sns.boxplot(data=df2, ax=axes[1], color='green') \n",
    "axes[1].set_title('Metric 2 Boxplot')\n",
    "\n",
    "# Box plot for metric 3\n",
    "sns.boxplot(data=df3, ax=axes[2], color='blue')\n",
    "axes[2].set_title('Metric 3 Boxplot')\n",
    "\n",
    "plt.suptitle('Box Plots for all the Metrics')\n",
    "\n",
    "plt.tight_layout()  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42366f22-cf2d-485b-b261-50cc7a751bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to check for outliers\n",
    "columns = ['Quantity', 'Impressions', 'Clicks']\n",
    "\n",
    "outliers_info = {}\n",
    "\n",
    "for column in columns:\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1 \n",
    "    \n",
    "    # boundaries for outliers\n",
    "    lower_bound = Q1 - (1.5 * IQR) \n",
    "    upper_bound = Q3 + (1.5 * IQR) \n",
    "    \n",
    "    # Finding of outliers\n",
    "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
    "   \n",
    "    outliers_info[column] = {\n",
    "        \"lower_bound\": lower_bound,\n",
    "        \"upper_bound\": upper_bound,\n",
    "        \"outliers_count\": len(outliers), \n",
    "        \"outliers\": outliers[[column, 'Day Index']] \n",
    "    }\n",
    "\n",
    "# outlier values\n",
    "for column in columns:\n",
    "    info = outliers_info[column] \n",
    "    print(f\"\\n{column} Outliers:\")\n",
    "    print(\"Lower bound:\", info[\"lower_bound\"])\n",
    "    print(\"Upper bound:\", info[\"upper_bound\"])\n",
    "    print(\"Number of outliers:\", info[\"outliers_count\"])\n",
    "    print(info[\"outliers\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ef4ffa-f296-4232-a7c6-824fd8439d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile_96_value = df[\"Quantity\"].quantile(0.98)\n",
    "\n",
    "print(percentile_96_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc5067f-b5e3-4d73-8aaf-eaded2aa0f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_outliers_98th_percentile(series):\n",
    "    q1, q3 = series.quantile([0.25, 0.75])\n",
    "    IQR = q3 - q1\n",
    "    lower_bound, upper_bound = q1 - 1.5 * IQR, q3 + 1.5 * IQR\n",
    "    percentile_96_value = series.quantile(0.98)\n",
    "    return series.apply(lambda x: percentile_96_value if x < lower_bound or x > upper_bound else x)\n",
    "df['New_Quantity'] = impute_outliers_98th_percentile(df['Quantity'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd4a3ad-cbf0-41dc-90f5-ba955181603c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Outliers in each dependent attribute:\")\n",
    "\n",
    "def column_to_check(data):\n",
    "    Q1 = data.quantile(0.25)\n",
    "    Q3 = data.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return data[(data < lower_bound) | (data > upper_bound)]\n",
    "\n",
    "quantity_outliers = column_to_check(df['New_Quantity'])\n",
    "print(f\"Quantity Outliers after imputation: {len(quantity_outliers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c7f756-9179-4c21-bca5-d9789d2d2521",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9048637-8c24-47d2-8d3b-ffe1712852ac",
   "metadata": {},
   "source": [
    "# Plotting Graph After Outlier Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542c5266-e76e-465c-a103-fb98b4f88543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of DayIndex vs New_Quantity\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df['Day Index'], df['New_Quantity'], marker='o', linestyle='-', color='blue', label='New_Quantity (Sales)')\n",
    "plt.title('DayIndex vs Sales', fontsize=16)\n",
    "plt.xlabel('DayIndex', fontsize=14)\n",
    "plt.ylabel('Sales', fontsize=14)\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40377b34-18b3-401e-abc0-fb52064098d2",
   "metadata": {},
   "source": [
    " * Reduced Fluctuation: The second graph shows a smoother pattern with less extreme fluctuations compared to the first graph. This is likely due to the removal of outliers, which can significantly impact the overall trend and variability of the data.\n",
    " * Potential for a Weak Upward Trend: The second graph might suggest a very slight upward trend in sales, which was not apparent in the first graph. This could indicate a gradual increase in sales over time, but further analysis with additional data points would be needed to confirm this trend.\n",
    " * Caution on Interpretation: It's important to remember that removing outliers can sometimes distort the true nature of the data. While it can help identify underlying patterns, it's crucial to consider the potential impact of outlier removal on the overall analysis. It's recommended to investigate the reasons for the outliers and their potential impact on the conclusions drawn from the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbefb00-9a3c-4c77-800d-bd4b21c47771",
   "metadata": {},
   "source": [
    "# Feature Engineering And EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b073f7-a566-4aee-ad24-e484b21fe76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Day Index'] = pd.to_datetime(df['Day Index'], format='%d-%m-%Y')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a97f6a-56bc-4121-869d-82415f3c0748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating weekends column, 1 if the day is a weekend (Saturday or Sunday) or else 0\n",
    "df['weekends'] = df['Day Index'].dt.weekday >= 5\n",
    "\n",
    "# Creating columns for each day of the week (Mon, Tue, Wed, Thu, Fri, Sat, Sun)\n",
    "df['mon'] = (df['Day Index'].dt.dayofweek == 0).astype(int)  \n",
    "df['tue'] = (df['Day Index'].dt.dayofweek == 1).astype(int)  \n",
    "df['wed'] = (df['Day Index'].dt.dayofweek == 2).astype(int)  \n",
    "df['thur'] = (df['Day Index'].dt.dayofweek == 3).astype(int) \n",
    "df['fri'] = (df['Day Index'].dt.dayofweek == 4).astype(int)  \n",
    "df['sat'] = (df['Day Index'].dt.dayofweek == 5).astype(int)  \n",
    "df['sun'] = (df['Day Index'].dt.dayofweek == 6).astype(int)  \n",
    "\n",
    "# Creating columns for each month (Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec)\n",
    "df['jan'] = (df['Day Index'].dt.month == 1).astype(int)\n",
    "df['feb'] = (df['Day Index'].dt.month == 2).astype(int)\n",
    "df['march'] = (df['Day Index'].dt.month == 3).astype(int)\n",
    "df['april'] = (df['Day Index'].dt.month == 4).astype(int)\n",
    "df['may'] = (df['Day Index'].dt.month == 5).astype(int)\n",
    "df['june'] = (df['Day Index'].dt.month == 6).astype(int)\n",
    "df['july'] = (df['Day Index'].dt.month == 7).astype(int)\n",
    "df['august'] = (df['Day Index'].dt.month == 8).astype(int)\n",
    "df['sep'] = (df['Day Index'].dt.month == 9).astype(int)\n",
    "df['oct'] = (df['Day Index'].dt.month == 10).astype(int)\n",
    "df['nov'] = (df['Day Index'].dt.month == 11).astype(int)\n",
    "df['dec'] = (df['Day Index'].dt.month == 12).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be2e1bf-f245-49f5-bbe0-674a91d38aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad876f4e-b136-46d0-bdfb-2ceb04cb2fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['day'] = pd.to_datetime(df['Day Index']).dt.day_name()\n",
    "\n",
    "df_grouped = df.groupby('day').agg({\n",
    "    'Quantity': 'sum',\n",
    "    'Impressions': 'sum',\n",
    "    'Clicks': 'sum',\n",
    "    'New_Quantity': 'sum',\n",
    "}).reset_index()\n",
    "\n",
    "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "df_grouped['day'] = pd.Categorical(df_grouped['day'], categories=day_order, ordered=True)\n",
    "df_grouped = df_grouped.sort_values('day').reset_index(drop=True)\n",
    "\n",
    "print(df_grouped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78846fa4-f933-4ee6-8656-a69d1a089333",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month'] = pd.to_datetime(df['Day Index']).dt.month_name()\n",
    "months_to_include = ['December', 'January', 'February', 'March', 'April', 'May', 'June']\n",
    "df = df[df['month'].isin(months_to_include)]\n",
    "df_monthly = df.groupby('month').agg({\n",
    "    'Quantity': 'sum',      \n",
    "    'Impressions': 'sum',    \n",
    "    'Clicks': 'sum',         \n",
    "    'New_Quantity': 'sum',   \n",
    "}).reset_index()\n",
    "\n",
    "month_order = ['December', 'January', 'February', 'March', 'April', 'May', 'June']\n",
    "df_monthly['month'] = pd.Categorical(df_monthly['month'], categories=month_order, ordered=True)\n",
    "df_monthly = df_monthly.sort_values('month').reset_index(drop=True)\n",
    "\n",
    "print(df_monthly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba8ee48-44dc-4ff1-b722-14b78396435e",
   "metadata": {},
   "source": [
    "# Plotting Graphs And Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f333a662-fe6f-487a-a7d9-fef5c53c4936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the line graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df_grouped['day'], df_grouped['Quantity'], marker='o', linestyle='-', color='b', label='Sales')\n",
    "plt.title('Sales by Day of the Week', fontsize=16)\n",
    "plt.xlabel('Day of the Week', fontsize=14)\n",
    "plt.ylabel('Sales (Quantity)', fontsize=14)\n",
    "plt.xticks(rotation=45)  \n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fc97fc-2d91-4d6c-8474-a1a8b2635c48",
   "metadata": {},
   "source": [
    "###\n",
    "* **Sales drop on Tuesday:** There is a significant fall in the quantity of sales on Tuesday, the lowest throughout the week. This may be a signal of lower customer activity or interaction on Tuesdays due to lower demand or preference at the very start of the workweek.\n",
    "* **Sales Recovery and Growth Midweek:** Quantities sold are likely to start growing from Wednesday to Saturday. This growth might be some sort of mid-week recovery, where closer to the weekend, the pace of customers picks up.\n",
    "* **Peak Sales on Friday and Saturday:** The graph illustrates that the peak sales occur on Friday and Saturday. This can be explained by the sudden rush of consumer activity before the weekend, as people are more engaged in purchasing something or enjoying some form of leisure activity.\n",
    "* **Sunday Slows Down:** A minor decline is seen on Sundays in the quantities sold, which may indicate a typical weekend slowdown in anticipation of the coming week. This may signal less consumer activities occur on Sundays.\n",
    "* Overall, sales are higher during the weekend than during the week. The overall pattern is that sales for weekends-that include Fridays and Saturdays-are higher compared to other days. This can be explained by the increased spending due to free time during weekends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9899917b-fbcf-465c-ad74-f292604c3b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the line graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df_monthly['month'], df_monthly['Quantity'], marker='o', linestyle='-', color='g', label='Sales')\n",
    "plt.title('Sales by Month', fontsize=16)\n",
    "plt.xlabel('Month', fontsize=14)\n",
    "plt.ylabel('Sales (Quantity)', fontsize=14)\n",
    "plt.xticks(rotation=45)  \n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd74f0f-5994-4926-9d46-f105040a834e",
   "metadata": {},
   "source": [
    "###\n",
    "* **Trend Analysis:** There appears to be a rise in sales from December to April, which peaks around April, from which sales drastically go down throughout May and June.\n",
    "* **Seasonal Pattern:** The increase in sales from December through April may depict seasonal demand, because of holidays or other factors.             \n",
    "* **Sudden Fall:** The drop from April to June is sharp; hence, this could be due to seasonal or market factors that caused a drop in demand, a change in consumer behavior, or probably some stock or supply issues.                                                                              \n",
    "* **Recommendation:** Companies, if this fall from April onwards is predictable, would prepare for those by adjusting their inventories or marketing strategy to lessen the impact of reduced sales during these months.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0e9bf7-3b85-422c-81f2-eb72a944f4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot for Clicks vs Impressions\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.scatter(df['Clicks'], df['Impressions'], color='blue', alpha=0.6, edgecolor='k')\n",
    "plt.title('Clicks vs Impressions', fontsize=14)\n",
    "plt.xlabel('Clicks', fontsize=12)\n",
    "plt.ylabel('Impressions', fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot for Impressions vs New_Quantity\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.scatter(df['New_Quantity'], df['Impressions'], color='green', alpha=0.6, edgecolor='k')\n",
    "plt.title('Sales vs Impressions', fontsize=14)\n",
    "plt.xlabel('Sales', fontsize=12)\n",
    "plt.ylabel('Impressions', fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot for New_Quantity vs Clicks\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.scatter(df['New_Quantity'], df['Clicks'], color='red', alpha=0.6, edgecolor='k')\n",
    "plt.title('Sales vs Clicks', fontsize=14)\n",
    "plt.xlabel('Sales', fontsize=12)\n",
    "plt.ylabel('Clicks', fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d7eb8b-a5df-4fc6-912b-2cdf2947f43a",
   "metadata": {},
   "source": [
    "###\n",
    "**Clicks vs Impressions**\n",
    "* The graph is scattered, and no line indicates a linear relationship between Clicks and Impressions. This means increased Impressions do not necessarily signify increased Clicks.\n",
    "* The clicks range from about 50 to 700, while impressions range between 500 and 2500-that is a big spread.\n",
    "* The distribution here would hence indicate that there could be an opportunity to investigate specific data clusters with a view to understand what kind of content performs well in certain ranges, which may be useful for better targeting and content optimization.\n",
    "   \n",
    "**Sales vs Impressions**\n",
    "* Generally speaking, the more impressions, the more sales.\n",
    "* This may suggest that the high marketing and visibility propel the sales upwards.\n",
    "* The scattered nature of the data points shows that other factors, other than impressions, are also quite crucial, like the quality of the product, its pricing, and marketing strategies.                                                                                                              \n",
    "\n",
    "**Sales vs Clicks**\n",
    "* There is some form of positive correlation between Sales and Clicks. This is because an increased number of clicks calls for an increased propensity in the number of sales.\n",
    "* Most of the data points are scattered, showing that sales can be influenced not only by clicks but even by other factors.\n",
    "* Data points show clusters, which tend to suggest that most sales levels will revolve around certain ranges of clicks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d06db2-7af5-44c0-a1ca-0935188abea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar graph for New_Quantity and Impressions\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(df.index - 0.2, df['New_Quantity'], width=0.4, label='Sales', color='blue', alpha=0.7)\n",
    "plt.bar(df.index + 0.2, df['Impressions'], width=0.4, label='Impressions', color='green', alpha=0.7)\n",
    "plt.title('Sales vs Impressions', fontsize=16)\n",
    "plt.xlabel('Index', fontsize=14)\n",
    "plt.ylabel('Values', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Bar graph for New_Quantity and Clicks\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(df.index - 0.2, df['New_Quantity'], width=0.4, label='Sales', color='blue', alpha=0.7)\n",
    "plt.bar(df.index + 0.2, df['Clicks'], width=0.4, label='Clicks', color='red', alpha=0.7)\n",
    "plt.title('Sales vs Clicks', fontsize=16)\n",
    "plt.xlabel('Index', fontsize=14)\n",
    "plt.ylabel('Values', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b3417c-a8a7-4ae4-9117-6a84869ba691",
   "metadata": {},
   "source": [
    "###\n",
    "**Sales vs Impressions**\n",
    "* There is a general trend where high impressions result in high sales, though it is not a linear relationship. The reason is that there are several points with a high level of impression that tend to have low sales, and vice versa.\n",
    "*  This is indicative of the fact that factors other than impression determine sales.Indeed, the chart points to the importance of impressions because these usually relate to increased sales. However, it should seriously be taken into consideration that the mere existence of impressions itself does not come out to be converted into sales.\n",
    "* There are other factors, too, such as product quality, pricing, marketing effectiveness, and customer sentiment, that have a major impact on sales, even with massive impression levels.\n",
    "                                                                                              \n",
    "**Sales vs Clicks**\n",
    "* The trend shows a consistent pattern where clicks are always higher than sales. This could indicate that while there is significant interest in the product or service, it is not converting into actual purchases.\n",
    "* The peak value for clicks is significantly higher than that for sales. This peak could be due to a specific marketing campaign or event that drove a lot of traffic but did not result in a proportional increase in sales.The data suggests that while marketing efforts are successful in attracting clicks, they may not be as effective in converting those clicks into sales.\n",
    "*  This could be due to various factors such as the quality of the landing page, the pricing of the product, or the overall user experience."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8bbbe9-6936-4856-bb98-c5573d6c5389",
   "metadata": {},
   "source": [
    "# Correalational Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf73ce0-3e2e-495c-b7bb-ca6b28004fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df[['New_Quantity', 'Impressions', 'Clicks']].corr()\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "plt.title('Correlation Heatmap', fontsize=16)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52324678-33ec-4d97-9093-b8866438e6e0",
   "metadata": {},
   "source": [
    "###\n",
    "* The above plot is a correlation heat map, showing the correlation coefficients between the New_Quantity, Impressions, and Clicks. This plot uses color gradients from blue to red, with blue representing the lowest and red the highest for that correlation. Also, numerically, these correlations have been shown inside the cells of the plotting.\n",
    "* All the variables perfectly correlate with themselves, as depicted by having a correlation coefficient of 1.00 and most saturated red color.       \n",
    "* **New_Quantity vs Impressions:** The New_Quantity and Impressions is related to the correlation coefficient value of 0.14. That can be inferred to mean that with more new quantity, the number of impressions tends to be on the higher side but very weakly.\n",
    "* **New_Quantity vs Clicks:** The correlation coefficient between New_Quntity and Clicks stands at 0.38, showing a moderately positive correlation. That infers that as the quantity of new items increases, the clicks have a fair increase.                                                        \n",
    "* **Impressions vs. Clicks:** The correlation coefficient between Impressions and Clicks is 0.03, showing a very weak positive correlation. This therefore implies that Impressions does not relate so much with Clicks.                                                                                 \n",
    "* Color gradient in this graph should be used for the interpretation of the strength of the correlations. Darker red shows stronger correlations, while lighter blue shows weaker correlations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51fb708-1cd2-4893-8b11-33e17547f508",
   "metadata": {},
   "source": [
    "# Stationarity Check and Train-Test Split\n",
    "### Stationarity Check  \n",
    "- Stationarity in time series refers to a constant mean, variance, and autocovariance over time, ensuring reliable statistical modeling. It is commonly tested using methods like the **Augmented Dickey-Fuller (ADF)** or **Kwiatkowski-Phillips-Schmidt-Shin (KPSS) tests**.\n",
    "\n",
    "### Train-Test Data  \n",
    "- Splitting time series data into train (used for model building) and test (used for validation) sets ensures unbiased evaluation of the model's predictive performance. A common practice is to allocate the last segment of the dataset as the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39134540-d552-4f0f-8ac7-b86a2923d653",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Day Index'] = pd.to_datetime(df['Day Index'])\n",
    "df.set_index('Day Index', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e608238-25b8-4f9c-8542-cb56579f15a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "test_result=adfuller(df['New_Quantity'])\n",
    "def adfuller_test(sales):\n",
    "    result=adfuller(sales)\n",
    "    labels = ['ADF Test Statistic','p-value','#Lags Used','Number of Observations Used']\n",
    "    for value, label in zip(result, labels):\n",
    "        print(label+': '+str(value))\n",
    "    if result[1] <= 0.05:\n",
    "        print(\"Data is stationary\")\n",
    "    else:\n",
    "        print(\"Data is non stationary\")\n",
    "\n",
    "adfuller_test(df['New_Quantity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4034cd9-6cca-4f16-bfb5-99cf2bc48d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['New_Quantity'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bab13c-ce7a-442e-84c2-0d0aa4478f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.iloc[:-int(len(df) * 0.2)]  # First 80% as train\n",
    "test = df.iloc[-int(len(df) * 0.2):] \n",
    "train['New_Quantity'] = pd.to_numeric(train['New_Quantity'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a486e693-d816-44f4-8065-562ad4467f29",
   "metadata": {},
   "source": [
    "## AR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784e728d-ae82-4c3c-9dda-0280828427ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df['New_Quantity'][:-int(len(df) * 0.2)] \n",
    "test = df['New_Quantity'][-int(len(df) * 0.2):] \n",
    "\n",
    "model = AutoReg(train, lags=1) \n",
    "model_fit = model.fit()\n",
    "\n",
    "print(model_fit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98e9455-5e1d-48a1-8ffe-24be804448ab",
   "metadata": {},
   "source": [
    "### AR Model Forecast And Error Percentage Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfa4250-e847-4fe5-88e9-f30ecfa88a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_fit.predict(start=len(train), end=len(df)-1, dynamic=False)\n",
    "\n",
    "# Plot of actual vs predicted values\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(test.index, test, label='Actual', color='blue')\n",
    "plt.plot(test.index, predictions, label='Predicted', color='red', linestyle='--')\n",
    "plt.title('AR Model: Actual vs Predicted')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('New_Quantity')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2bc199-b6d3-4271-9726-f8bb7b68d0aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ar_rmse = np.sqrt(mean_squared_error(test, predictions))\n",
    "ar_mae = mean_absolute_error(test, predictions)\n",
    "ar_mape = np.mean(np.abs((test - predictions) / test)) * 100\n",
    "\n",
    "print(f\"RMSE: {ar_rmse}\")\n",
    "print(f\"MAE: {ar_mae}\")\n",
    "print(f\"MAPE: {ar_mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863de3ee-28c9-4e9f-980d-6802e8f419e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df['New_Quantity']\n",
    "train_size = int(len(data) * 0.8)\n",
    "train_data = data[:train_size]\n",
    "test_data = data[train_size:]\n",
    "\n",
    "best_lag = None\n",
    "best_rmse = float('inf')\n",
    "\n",
    "for lag in range(1, 21):\n",
    "    model = AutoReg(train_data, lags=lag)\n",
    "    model_fit = model.fit()\n",
    "    predictions = model_fit.predict(start=len(train_data), end=len(train_data) + len(test_data) - 1)\n",
    "    rmse = np.sqrt(mean_squared_error(test_data, predictions))\n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        best_lag = lag\n",
    "\n",
    "print(\"Best Lag:\", best_lag)\n",
    "print(\"Best RMSE:\", best_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db9593c-dc7e-465d-ba09-5993fe293da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = AutoReg(data, lags=best_lag).fit()\n",
    "predictions = best_model.predict(start=best_lag, end=len(data) - 1)\n",
    "aligned_actual = data[best_lag:len(predictions) + best_lag]\n",
    "ar_tuned_rmse = np.sqrt(mean_squared_error(aligned_actual, predictions))\n",
    "ar_tuned_mae = mean_absolute_error(aligned_actual, predictions)\n",
    "ar_tuned_mape = np.mean(np.abs((aligned_actual - predictions) / aligned_actual)) * 100\n",
    "\n",
    "print(f\"RMSE of the optimized model: {ar_tuned_rmse:.4f}\")\n",
    "print(f\"MAE of the optimized model: {ar_tuned_mae:.4f}\")\n",
    "print(f\"MAPE of the optimized model: {ar_tuned_mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7204f154-5523-4a26-ba18-ca8d7fcec5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(aligned_actual.index, aligned_actual, label='Actual', color='blue')\n",
    "plt.plot(aligned_actual.index, predictions, label='Predicted', color='orange', linestyle='--')\n",
    "plt.title('Tuned AR Model: Actual vs Predicted', fontsize=16)\n",
    "plt.xlabel('Time', fontsize=14)\n",
    "plt.ylabel('New_Quantity', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5e97a7-ee8f-48d0-8f24-92d8e9e540f0",
   "metadata": {},
   "source": [
    "1. **RMSE (4.85)**: Indicates moderate prediction errors.  \n",
    "2. **MAPE (26.67%)**: Suggests the model's predictions deviate by ~26.6%, showing room for improvement.  \n",
    "3. **Plot Observation**: The flat predicted line fails to capture the variability in actual data, signaling a need for a more robust model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5f6189-eec5-451d-9002-44a243988e88",
   "metadata": {},
   "source": [
    "## MA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f340638-d5c0-4b27-bf3e-5a0f62099d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining MA model\n",
    "train = df.iloc[:-int(len(df) * 0.2)]  # First 80% as train\n",
    "test = df.iloc[-int(len(df) * 0.2):] \n",
    "ma_model = ARIMA(train['New_Quantity'], order=(0, 0, 2)) \n",
    "ma_results = ma_model.fit()\n",
    "\n",
    "# Print of model summary\n",
    "print(ma_results.summary())\n",
    "\n",
    "# Forecasting values for the test set\n",
    "forecast = ma_results.forecast(steps=len(test))\n",
    "print(forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6abd109-59bb-485d-88e0-d53be08b401a",
   "metadata": {},
   "source": [
    "### MA Model Forecast And Error Percentage Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160eaeb7-7968-448c-a0f1-fcb1a75bcca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(test.index, test['New_Quantity'], label=\"Actual (Test Data)\", color=\"blue\")\n",
    "plt.plot(test.index, forecast, label=\"Forecast (MA Model)\", color=\"red\", linestyle=\"--\")\n",
    "plt.title(\"MA Model - Actual vs Forecast\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"New_Quantity\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae49045-f1a4-4af5-87b0-acb7527840b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_aligned = test['New_Quantity'].iloc[:len(forecast)]\n",
    "ma_rmse = np.sqrt(mean_squared_error(test_aligned, forecast))\n",
    "ma_mae = mean_absolute_error(test_aligned, forecast)\n",
    "ma_mape = np.mean(np.abs((test_aligned - forecast) / test_aligned)) * 100\n",
    "# Print metrics\n",
    "print(f\"RMSE: {ma_rmse:.2f}\")\n",
    "print(f\"MAE: {ma_mae:.2f}\")\n",
    "print(f\"MAPE: {ma_mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5d3189-3190-49f8-bcdb-dc06c4aa9ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = range(1, 21)\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "best_q = None\n",
    "best_rmse = float('inf')\n",
    "for q in qs:\n",
    "    fold_rmse = []\n",
    "    for train_idx, test_idx in tscv.split(df['New_Quantity']):\n",
    "        train, test = df['New_Quantity'].iloc[train_idx], df['New_Quantity'].iloc[test_idx]\n",
    "        model = ARIMA(train, order=(0, 0, 2))\n",
    "        model_fit = model.fit()\n",
    "        predictions = model_fit.predict(start=len(train), end=len(train) + len(test) - 1)\n",
    "        fold_rmse.append(np.sqrt(mean_squared_error(test, predictions)))\n",
    "    \n",
    "    avg_rmse = np.mean(fold_rmse)\n",
    "    if avg_rmse < best_rmse:\n",
    "        best_rmse = avg_rmse\n",
    "        best_q = q\n",
    "\n",
    "print(f\"Optimal q : {best_q} with RMSE: {best_rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25a230a-3e10-4eca-99c0-5ffd5cb5172d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_model = ARIMA(train, order=(0, 0, best_q)).fit()\n",
    "tuned_predictions = tuned_model.predict(start=len(train), end=len(data)-1, dynamic=False)\n",
    "test_aligned = test.iloc[:len(tuned_predictions)]\n",
    "\n",
    "ma_tuned_rmse = np.sqrt(mean_squared_error(test_aligned, tuned_predictions))\n",
    "ma_tuned_mae = mean_absolute_error(test_aligned, tuned_predictions)\n",
    "ma_tuned_mape = np.mean(np.abs((test_aligned - tuned_predictions) / test_aligned)) * 100\n",
    "\n",
    "print(f\"Tuned MA Model RMSE: {ma_tuned_rmse:.2f}\")\n",
    "print(f\"Tuned MA Model MAE: {ma_tuned_mae:.2f}\")\n",
    "print(f\"Tuned MA Model MAPE: {ma_tuned_mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c34cae-6221-4f2b-b650-96e276ef7288",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(test_aligned.index, test_aligned, label='Actual', color='blue', linewidth=2)\n",
    "plt.plot(test_aligned.index, tuned_predictions, label='Predicted', color='orange', linestyle='--', linewidth=2)\n",
    "plt.title(f'Tuned MA Model', fontsize=16)\n",
    "plt.xlabel('Time', fontsize=14)\n",
    "plt.ylabel('New Quantity', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15321599-6ae2-4a27-b01c-1b42c9374107",
   "metadata": {},
   "source": [
    "1. **RMSE (4.63)**: Indicates moderate prediction errors;  \n",
    "2. **MAPE (32.36%)**: Suggests the model's predictions deviate by ~33.47%, showing room for improvement.  \n",
    "3. **Plot Observation**: The flat predicted line fails to capture the variability in actual data, signaling a need for a more robust model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f560c28-4708-4839-b420-856e56322431",
   "metadata": {},
   "source": [
    "## ARIMA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ee6804-78d8-494a-a3f6-c2021199b0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.iloc[:-int(len(df) * 0.2)].copy() \n",
    "test = df.iloc[-int(len(df) * 0.2):].copy() \n",
    "stepwise_fit = auto_arima (df['New_Quantity'], trace=True, suppress_warnings=True)\n",
    "print(stepwise_fit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5403cba4-895a-4639-9d6a-051d6c1efc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ARIMA(train['New_Quantity'], order=(1, 0, 1))\n",
    "model_fit = model.fit()\n",
    "print(model_fit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5a73f1-3699-4900-a7aa-95ad2e3b8dd7",
   "metadata": {},
   "source": [
    "### ARIMA Model Forecast "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f732dd-02ee-4eab-86c9-d78f21f823d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = len(train)\n",
    "end = len(train) + len(test) - 1\n",
    "pred = model_fit.predict(start=start,end=end,typ='levels')\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c2f3c1-a829-441d-89b2-560d38cd18e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.plot(legend=True)\n",
    "test['New_Quantity'].plot(legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfec23a-76e7-4bdf-8d6d-aa908b2ba9f4",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning(With Error Percentage Calculation) And Residual Plot Of ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f603a901-deed-47ae-8e06-875c6a1acb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_rmse = np.sqrt(mean_squared_error(test['New_Quantity'], pred))\n",
    "arima_mae = mean_absolute_error(test['New_Quantity'], pred)\n",
    "arima_mape = np.mean(np.abs((test['New_Quantity'] - pred) / test['New_Quantity'])) * 100\n",
    "\n",
    "print(f\"Basic ARIMA Model RMSE: {arima_rmse:.2f}\")\n",
    "print(f\"Basic ARIMA Model MAE: {arima_mae:.2f}\")\n",
    "print(f\"Basic ARIMA Model MAPE: {arima_mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a039e0-7aea-447b-b2e9-a191ab0cfab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values = range(0, 3)\n",
    "d_values = range(0, 3)\n",
    "q_values = range(0, 3)\n",
    "\n",
    "best_params = None\n",
    "best_rmse = float('inf')\n",
    "\n",
    "train_size = int(len(df) * 0.8)\n",
    "train = df['New_Quantity'][:train_size]  \n",
    "test = df['New_Quantity'][train_size:]\n",
    "\n",
    "for p in p_values:\n",
    "    for d in d_values:\n",
    "        for q in q_values:\n",
    "            try:\n",
    "                model = ARIMA(train, order=(p, d, q))\n",
    "                model_fit = model.fit()\n",
    "                predictions = model_fit.predict(start=len(train), end=len(train) + len(test) - 1, dynamic=False)\n",
    "                rmse = np.sqrt(mean_squared_error(test, predictions))\n",
    "                if rmse < best_rmse:\n",
    "                    best_rmse = rmse\n",
    "                    best_params = (p, d, q)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "print(f\"Best Parameters: p={best_params[0]}, d={best_params[1]}, q={best_params[2]} with RMSE: {best_rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9295282e-04ef-468e-868d-3b32e654acbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_p, best_d, best_q = best_params\n",
    "tuned_model = ARIMA(train, order=(best_p, best_d, best_q)).fit()\n",
    "\n",
    "tuned_predictions = tuned_model.predict(start=len(train), end=len(data)-1, dynamic=False)\n",
    "test_aligned = test.iloc[:len(tuned_predictions)] \n",
    "\n",
    "arima_tuned_rmse = np.sqrt(mean_squared_error(test_aligned, tuned_predictions))\n",
    "arima_tuned_mae = mean_absolute_error(test_aligned, tuned_predictions)\n",
    "arima_tuned_mape = np.mean(np.abs((test_aligned - tuned_predictions) / test_aligned)) * 100\n",
    "\n",
    "print(f\"Tuned ARIMA Model RMSE: {arima_tuned_rmse:.2f}\")\n",
    "print(f\"Tuned ARIMA Model MAE: {arima_tuned_mae:.2f}\")\n",
    "print(f\"Tuned ARIMA Model MAPE: {arima_tuned_mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ddad58-2964-407c-9690-310dc5e583e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(test_aligned.index, test_aligned, label='Actual', color='blue', linewidth=2)\n",
    "plt.plot(test_aligned.index, tuned_predictions, label='Predicted', color='orange', linestyle='--', linewidth=2)\n",
    "plt.title(f'Tuned ARIMA Model (p={best_p}, d={best_d}, q={best_q}): Actual vs Predicted', fontsize=16)\n",
    "plt.xlabel('Time', fontsize=14)\n",
    "plt.ylabel('New Quantity', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465c43f2-d497-4c65-a28a-d0a2aa92c7c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p = 1 \n",
    "d = 0  \n",
    "q = 1\n",
    "arima_model = ARIMA(df['New_Quantity'], order=(p, d, q)).fit()\n",
    "residuals = arima_model.resid\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(residuals)\n",
    "plt.title('Residuals Plot')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Residuals')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d968eb-fb78-490e-8146-640cc01efeb8",
   "metadata": {},
   "source": [
    "1. **Residual Plot Observation**: The residuals fluctuate around zero but show some variability, suggesting the model is not fully capturing the patterns in the data.  \n",
    "\n",
    "2. **MAPE (21.39%)**: Indicates a slight improvement in percentage error compared to previous models, but accuracy still needs enhancement.  \n",
    "\n",
    "3. **RMSE (3.53)**: Higher than the earlier models, signaling an increase in prediction errors despite better percentage error (MAPE)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3310b783-5572-4bce-805c-3c155e341d5e",
   "metadata": {},
   "source": [
    "### SARIMA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7994b53-50a0-44ab-a69c-594c88438df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "from  pandas.plotting import register_matplotlib_converters\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "register_matplotlib_converters()\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9675b64-eb0f-4d9d-bf9a-1fd537a374b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.iloc[:-int(len(df) * 0.2)]\n",
    "test = df.iloc[-int(len(df) * 0.2):]\n",
    "sarima_model = SARIMAX(train['New_Quantity'], order=(1, 1, 1), seasonal_order=(1, 1, 1, 12))\n",
    "sarima_result = sarima_model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3096b221-d385-4d1d-b061-fd5dafc6edfd",
   "metadata": {},
   "source": [
    "### Plotting Forescat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385eb5ac-3e3c-4ff9-808d-00dad88af5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = sarima_result.forecast(steps=len(test))\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(test.index, test['New_Quantity'], label='Observed', color='blue')\n",
    "plt.plot(test.index, forecast, label='Forecast', color='orange', linestyle='--')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66296c15-00a9-46b8-bf69-a279e10b1a94",
   "metadata": {},
   "source": [
    "**Plot Observation:** The graph shows that the SARIMA model is able to capture the overall trend and seasonality of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9341de40-06f0-412f-980d-6be844eb6414",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning(With Error Percentage Calculation) And Residual Plot Of SARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dfd20f-8a23-4a51-9d69-70d863661359",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = sarima_result.predict(start=len(train), end=len(df)-1, dynamic=False)\n",
    "test_actual = test['New_Quantity']\n",
    "\n",
    "sarima_rmse = np.sqrt(mean_squared_error(test_actual, predictions))\n",
    "sarima_mae = mean_absolute_error(test_actual, predictions)\n",
    "sarima_mape = np.mean(np.abs((test_actual - predictions) / test_actual)) * 100\n",
    "\n",
    "print(f\"RMSE: {sarima_rmse:.2f}\")\n",
    "print(f\"MAE: {sarima_mae:.2f}\")\n",
    "print(f\"MAPE: {sarima_mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6c0c5c-aa4c-4fdf-9d27-fd0ad975d9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train-test\n",
    "data = df['New_Quantity']\n",
    "train_size = int(len(data) * 0.8)\n",
    "train = data[:train_size]\n",
    "test = data[train_size:]\n",
    "\n",
    "# Parameter ranges for SARIMA\n",
    "p = range(0, 3)\n",
    "d = range(0, 2)\n",
    "q = range(0, 3)\n",
    "P = range(0, 2)\n",
    "D = range(0, 2)\n",
    "Q = range(0, 2)\n",
    "s = [12]  \n",
    "\n",
    "best_params = None\n",
    "best_rmse = float('inf')\n",
    "\n",
    "for p_val in p:\n",
    "    for d_val in d:\n",
    "        for q_val in q:\n",
    "            for P_val in P:\n",
    "                for D_val in D:\n",
    "                    for Q_val in Q:\n",
    "                        for season in s:\n",
    "                            try:\n",
    "                                model = SARIMAX(\n",
    "                                    train,\n",
    "                                    order=(p_val, d_val, q_val),\n",
    "                                    seasonal_order=(P_val, D_val, Q_val, season),\n",
    "                                    enforce_stationarity=False,\n",
    "                                    enforce_invertibility=False\n",
    "                                )\n",
    "                                model_fit = model.fit(disp=False)\n",
    "\n",
    "                                predictions = model_fit.predict(start=len(train), end=len(data)-1, dynamic=False)\n",
    "                                test_aligned = test.iloc[:len(predictions)]\n",
    "\n",
    "                                rmse = np.sqrt(mean_squared_error(test_aligned, predictions))\n",
    "                                if rmse < best_rmse:\n",
    "                                    best_rmse = rmse\n",
    "                                    best_params = ((p_val, d_val, q_val), (P_val, D_val, Q_val, season))\n",
    "                            except Exception as e:\n",
    "                                print(f\"Error for SARIMA{(p_val, d_val, q_val)} x Seasonal{(P_val, D_val, Q_val, season)}: {e}\")\n",
    "                                continue\n",
    "\n",
    "print(f\"Best Parameters: ARIMA{best_params[0]} x Seasonal{best_params[1]} with RMSE: {best_rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c330cf47-0fcf-4388-844b-50ccbf6ccef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_order, best_seasonal_order = best_params\n",
    "\n",
    "tuned_model = SARIMAX(train, order=best_order, seasonal_order=best_seasonal_order).fit()\n",
    "\n",
    "tuned_predictions = tuned_model.predict(start=len(train), end=len(data)-1, dynamic=False)\n",
    "test_aligned = test.iloc[:len(tuned_predictions)].copy() \n",
    "\n",
    "sarima_tuned_rmse = np.sqrt(mean_squared_error(test_aligned, tuned_predictions))\n",
    "sarima_tuned_mae = mean_absolute_error(test_aligned, tuned_predictions)\n",
    "sarima_tuned_mape = np.mean(np.abs((test_aligned - tuned_predictions) / test_aligned)) * 100\n",
    "\n",
    "print(f\"Tuned SARIMA Model RMSE: {sarima_tuned_rmse:.2f}\")\n",
    "print(f\"Tuned SARIMA Model MAE: {sarima_tuned_mae:.2f}\")\n",
    "print(f\"Tuned SARIMA Model MAPE: {sarima_tuned_mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a2b1f4-6b23-4213-8d34-535e24a8c5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(test_aligned.index, test_aligned, label='Actual', color='blue', linewidth=2)\n",
    "plt.plot(test_aligned.index, tuned_predictions, label='Predicted', color='orange', linestyle='--', linewidth=2)\n",
    "plt.title(f'Tuned SARIMA Model (Order={best_order}, Seasonal={best_seasonal_order}): Actual vs Predicted', fontsize=16)\n",
    "plt.xlabel('Time', fontsize=14)\n",
    "plt.ylabel('New Quantity', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ddf10a-f674-4ac5-9b2f-669db1ce5a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = sarima_result.resid\n",
    "\n",
    "# Plot residuals\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Residual plot \n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(residuals)\n",
    "plt.title('Residuals Plot')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Residuals')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d85ad2-ef55-46af-8054-374b7c00fb6d",
   "metadata": {},
   "source": [
    "**1. Residuals Plot:** In this plot, we can see that the residuals are not evenly distributed around zero. There are some clusters of points above and below zero, which suggests that the model may not be capturing all of the underlying patterns in the data.\n",
    "\n",
    "**2. RMSE:** The RMSE is 3.42, which is relatively high. This suggests that the model is not a very good fit for the data.\n",
    "\n",
    "**3. MAE:** The MAE is 2.77, which is also relatively high. This again suggests that the model is not a very good fit for the data.\n",
    "\n",
    "**4. MAPE:** The MAPE is 22.41%, which is very high. This suggests that the model is a very poor fit for the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e555e21-553a-459e-933b-5fbf1a903efe",
   "metadata": {},
   "source": [
    "# ARIMAX Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6dff4b-13e5-4cfa-bc61-e02aba6d8a5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#  dependent variable\n",
    "y = df['New_Quantity']\n",
    "\n",
    "# exogenous variables\n",
    "exog = df[['Impressions', 'Clicks', 'mon', 'tue', 'wed', 'thur', 'fri', 'sat', 'sun', 'jan', 'feb', 'march', 'april', \n",
    "           'may', 'june', 'july', 'august', 'sep', 'oct', 'nov', 'dec']]\n",
    "train_size = int(len(df) * 0.8)\n",
    "train = df.iloc[:train_size]\n",
    "test = df.iloc[train_size:]\n",
    "arimax_model = ARIMA(train['New_Quantity'], order=(1, 0, 1), exog=train[['Impressions', 'Clicks', 'mon', 'tue', 'wed', 'thur', 'fri', 'sat', 'sun', 'jan', 'feb', 'march', 'april', \n",
    "           'may', 'june', 'july', 'august', 'sep', 'oct', 'nov', 'dec']]).fit()\n",
    "\n",
    "# Forecast on test data\n",
    "forecast = arimax_model.forecast(\n",
    "    steps=len(test), \n",
    "    exog=test[['Impressions', 'Clicks', 'mon', 'tue', 'wed', 'thur', 'fri', 'sat', 'sun', 'jan', 'feb', 'march', 'april', \n",
    "           'may', 'june', 'july', 'august', 'sep', 'oct', 'nov', 'dec']]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb9b880-30ad-47b6-bf84-55e5797a8c8d",
   "metadata": {},
   "source": [
    "### Plotting Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8815b1ed-ec4f-4a05-8387-b30143dafcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24, 12))\n",
    "plt.plot(test.index, test['New_Quantity'], label='Observed', color='blue')\n",
    "plt.plot(test.index, forecast, label='Forecast (ARIMAX)', color='orange')\n",
    "plt.title('ARIMAX Model Fit (Test Set)')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('New_Quantity')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3697fcc-5946-4578-adcf-8dfe6269cfde",
   "metadata": {},
   "source": [
    "**ARIMAX Model Fit:** The ARIMAX model appears to capture the general trend and seasonality of the data.                                                                                       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04471f26-ec22-4920-a8da-7b6a156b2801",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning(With Error Percentage Calculation) And Residual Plot Of ARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8bea4a-33da-44a8-bd83-0b242e3caf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "arimax_rmse = np.sqrt(mean_squared_error(test['New_Quantity'], forecast))\n",
    "arimax_mae = mean_absolute_error(test['New_Quantity'], forecast)\n",
    "arimax_mape = np.mean(np.abs((test['New_Quantity'] - forecast) / test['New_Quantity'])) * 100\n",
    "\n",
    "# Print metrics\n",
    "print(f\"RMSE: {arimax_rmse:.2f}\")\n",
    "print(f\"MAE: {arimax_mae:.2f}\")\n",
    "print(f\"MAPE: {arimax_mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e33c8d-4eaa-4b6d-8ed5-5e94510039a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values = d_values = q_values = range(0, 3)\n",
    "best_rmse = float('inf')\n",
    "best_params = None\n",
    "\n",
    "train_size = int(len(df) * 0.8)\n",
    "train = df.iloc[:train_size]\n",
    "test = df.iloc[train_size:]\n",
    "\n",
    "exog_train = train[['Impressions', 'Clicks', 'mon', 'tue', 'wed', 'thur', 'fri', 'sat', 'sun', 'jan', 'feb', 'march', 'april', \n",
    "           'may', 'june', 'july', 'august', 'sep', 'oct', 'nov', 'dec']]\n",
    "exog_test = test[['Impressions', 'Clicks', 'mon', 'tue', 'wed', 'thur', 'fri', 'sat', 'sun', 'jan', 'feb', 'march', 'april', \n",
    "           'may', 'june', 'july', 'august', 'sep', 'oct', 'nov', 'dec']]\n",
    "\n",
    "for p in p_values:\n",
    "    for d in d_values:\n",
    "        for q in q_values:\n",
    "            try:\n",
    "                arimax_model = ARIMA(train['New_Quantity'], order=(p, d, q), exog=exog_train)\n",
    "                arimax_result = arimax_model.fit()\n",
    "                predictions = arimax_result.forecast(steps=len(test), exog=exog_test)\n",
    "                rmse = np.sqrt(mean_squared_error(test['New_Quantity'], predictions))\n",
    "                if rmse < best_rmse:\n",
    "                    best_rmse = rmse\n",
    "                    best_params = (p, d, q)\n",
    "            except Exception as e:\n",
    "                continue\n",
    "\n",
    "print(f\"The best parameters are: p={best_params[0]}, d={best_params[1]}, q={best_params[2]}\")\n",
    "print(f\"The best RMSE is: {best_rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d56ba7-7f23-4731-aa1f-b8e8e637acfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_p, best_d, best_q = best_params\n",
    "\n",
    "arimax_tuned_model = ARIMA(train['New_Quantity'], order=(best_p, best_d, best_q), exog=exog_train)\n",
    "arimax_tuned_result = arimax_tuned_model.fit()\n",
    "\n",
    "tuned_predictions = arimax_tuned_result.forecast(steps=len(test), exog=exog_test)\n",
    "\n",
    "# Calculation of error metrics\n",
    "arimax_tuned_rmse = np.sqrt(mean_squared_error(test['New_Quantity'], tuned_predictions))\n",
    "arimax_tuned_mae = mean_absolute_error(test['New_Quantity'], tuned_predictions)\n",
    "arimax_tuned_mape = np.mean(np.abs((test['New_Quantity'] - tuned_predictions) / test['New_Quantity'])) * 100\n",
    "\n",
    "print(f\"Tuned ARIMAX RMSE: {arimax_tuned_rmse:.2f}\")\n",
    "print(f\"Tuned ARIMAX MAE: {arimax_tuned_mae:.2f}\")\n",
    "print(f\"Tuned ARIMAX MAPE: {arimax_tuned_mape:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e247b4-a844-4e6a-a102-ed801b49bba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(test.index, test['New_Quantity'], label='Actual', color='blue', linewidth=2)\n",
    "plt.plot(test.index, tuned_predictions, label='Predicted', color='orange', linestyle='--', linewidth=2)\n",
    "plt.title(f'Tuned ARIMAX Model (p={best_p}, d={best_d}, q={best_q}) - Actual vs Predicted', fontsize=16)\n",
    "plt.xlabel('Time', fontsize=14)\n",
    "plt.ylabel('New Quantity', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9240d449-6b44-41ed-91a0-d4a8b0369f1f",
   "metadata": {},
   "source": [
    "**RMSE:** A lower RMSE means the model's predictions are, on average, closer to the actual values. The reduction in RMSE confirms that the tuned model is making more accurate forecasts.              \n",
    "**MAE:** Similar to RMSE, a lower MAE indicates better predictive accuracy. The decrease in MAE further supports the improved performance of the tuned model.                                     \n",
    "**MAPE:** A lower MAPE implies that the model's percentage errors are smaller. The reduction in MAPE shows that the tuned model is making more reliable predictions, especially in terms of relative error   \n",
    "**Residuals Plot:** In this plot, we can see that the residuals are not evenly distributed around zero. There are some clusters of points above and below zero, which suggests that the model may not be capturing all of the underlying patterns in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d86370-a536-4c01-a7f7-e9f14ac798e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = test['New_Quantity'] - tuned_predictions\n",
    "# Plot of residuals\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(residuals, label='Residuals', color='green')\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.title('Residuals of ARIMAX Model')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Residuals')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ecea35-1b90-4400-81f6-765721250ffa",
   "metadata": {},
   "source": [
    "# SARIMAX Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096cc8c2-a994-4362-907a-e21ed4b1d5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['New_Quantity'] \n",
    "exog = df[['Impressions', 'Clicks', 'mon', 'tue', 'wed', 'thur', 'fri', 'sat', 'sun', 'jan', 'feb', 'march', 'april', \n",
    "           'may', 'june', 'july', 'august', 'sep', 'oct', 'nov', 'dec']] \n",
    "train_size = int(len(df) * 0.8)\n",
    "train_y = y[:train_size]\n",
    "train_exog = exog[:train_size]\n",
    "test_y = y[train_size:]\n",
    "test_exog = exog[train_size:]\n",
    "\n",
    "sarimax_model = SARIMAX(train_y, \n",
    "                        order=(1, 0, 1),  \n",
    "                        seasonal_order=(1, 1, 1, 12),  \n",
    "                        exog=train_exog).fit()\n",
    "\n",
    "predictions = sarimax_model.predict(start=train_size, end=len(y)-1, exog=test_exog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deae0368-e998-441a-9157-4b09c5d308b0",
   "metadata": {},
   "source": [
    "### Plotting Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b626c68-2998-4578-ba08-16312d10ed4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6)) \n",
    "plt.plot(test_y.index, test_y, label='Actual', color='blue')\n",
    "plt.plot(test_y.index, predictions, label='Predicted', color='red')\n",
    "plt.title('SARIMAX Model: Actual vs Predicted ')\n",
    "plt.xlabel('Time')  \n",
    "plt.ylabel('New_Quantity')  \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efb936d-8ba5-46a3-aca0-5c3876ce91ef",
   "metadata": {},
   "source": [
    "**SARIMAX Model:** Overall, the ARIMAX model appears to be a decent fit for the data, capturing the overall trend and some of the seasonal patterns.                                              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827e0def-b3aa-4c09-9ae4-2051def27393",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning(With Error Percentage Calculation)  And Residual Plot Of SARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd4d531-a713-41bc-8772-0a8b4e9513a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = test_y\n",
    "y_pred = predictions\n",
    "\n",
    "sarimax_mae = mean_absolute_error(y_true, y_pred)\n",
    "sarimax_rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "sarimax_mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "print(f\"MAE: {sarimax_mae:.2f}\")\n",
    "print(f\"RMSE: {sarimax_rmse:.2f}\")\n",
    "print(f\"MAPE: {sarimax_mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c631126-718c-4f33-9e61-15249fc9282e",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values = q_values = range(0, 2)\n",
    "d_values = [0, 1]\n",
    "P_values = Q_values = range(0, 2)\n",
    "D_values = [0, 1]\n",
    "s_values = [12]  \n",
    "\n",
    "best_rmse = float('inf')\n",
    "best_params = None\n",
    "\n",
    "for p, d, q, P, D, Q, s in itertools.product(p_values, d_values, q_values, P_values, D_values, Q_values, s_values):\n",
    "    try:\n",
    "        model = SARIMAX(train_y, order=(p, d, q), seasonal_order=(P, D, Q, s), exog=train_exog)\n",
    "        result = model.fit(disp=False)\n",
    "        \n",
    "        predictions = result.predict(start=len(train_y), end=len(train_y) + len(test_y) - 1, exog=test_exog)\n",
    "        rmse = np.sqrt(mean_squared_error(test_y, predictions))\n",
    "        \n",
    "        if rmse < best_rmse:\n",
    "            best_rmse = rmse\n",
    "            best_params = (p, d, q, P, D, Q, s)\n",
    "\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Best RMSE: {best_rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26070ef4-2199-496a-a9fd-6cad5b208fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_p, best_d, best_q, best_P, best_D, best_Q, best_s = best_params\n",
    "\n",
    "sarimax_model = SARIMAX(train_y, \n",
    "                        order=(best_p, best_d, best_q),  \n",
    "                        seasonal_order=(best_P, best_D, best_Q, best_s),  \n",
    "                        exog=train_exog)\n",
    "sarimax_result = sarimax_model.fit(disp=False)\n",
    "\n",
    "predictions = sarimax_result.predict(start=train_size, end=len(y)-1, exog=test_exog)\n",
    "\n",
    "sarimax_tuned_mae = mean_absolute_error(test_y, predictions)\n",
    "sarimax_tuned_rmse = np.sqrt(mean_squared_error(test_y, predictions))\n",
    "sarimax_tuned_mape = np.mean(np.abs((test_y - predictions) / test_y)) * 100\n",
    "\n",
    "print(f\"Tuned MAE: {sarimax_tuned_mae:.2f}\")\n",
    "print(f\"Tuned RMSE: {sarimax_tuned_rmse:.2f}\")\n",
    "print(f\"Tuned MAPE: {sarimax_tuned_mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8b690f-7b1c-4d4c-a387-2f0e08cf68f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(test_y.index, test_y, label='Actual', color='blue')\n",
    "plt.plot(test_y.index, predictions, label='Predicted', color='orange')\n",
    "plt.title('Tuned SARIMAX Model: Actual vs Predicted')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('New Quantity')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ea8b74-b8c5-4a79-a675-b1c35876009f",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y - predictions\n",
    "# Plot of residuals\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(residuals)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.title('Residuals of the SARIMAX Model')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Residuals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22ef574-9617-40f7-b302-b6b52a9769fe",
   "metadata": {},
   "source": [
    "**RMSE:** A lower RMSE means the model's predictions are, on average, closer to the actual values. The reduction in RMSE confirms that the tuned model is making more accurate forecasts.              \n",
    "**MAE:** Similar to RMSE, a lower MAE indicates better predictive accuracy. The decrease in MAE further supports the improved performance of the tuned model.                                     \n",
    "**MAPE:** A lower MAPE implies that the model's percentage errors are smaller. The reduction in MAPE shows that the tuned model is making more reliable predictions, especially in terms of relative error   \n",
    "**Residuals Plot:** In this plot, we can see that the residuals are not evenly distributed around zero. There are some clusters of points above and below zero, which suggests that the model may not be capturing all of the underlying patterns in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f1c1d5-86b7-48c5-abb8-5b659995fdc7",
   "metadata": {},
   "source": [
    "# Analysis Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb68129-7cd1-4993-ac15-c40e57f5c35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {\n",
    "    'Model_name': ['ar', 'ma', 'arima', 'sarima', 'arimax', 'sarimax'],\n",
    "    'mae': [ar_mae, ma_mae,arima_mae, sarima_mae, arimax_mae, sarimax_mae],\n",
    "    'rmse': [ar_rmse, ma_rmse, arima_rmse, sarima_rmse, arimax_rmse, sarimax_rmse],\n",
    "    'mape': [ar_mape, ma_mape, arima_mape, sarima_mape, arimax_mape, sarimax_mape],\n",
    "    'tuned_mae': [ar_tuned_mae, ma_tuned_mae, arima_tuned_mae, sarima_tuned_mae, arimax_tuned_mae, sarimax_tuned_mae],\n",
    "    'tuned_rmse': [ar_tuned_rmse, ma_tuned_rmse, arima_tuned_rmse, sarima_tuned_rmse, arimax_tuned_rmse, sarimax_tuned_rmse],\n",
    "    'tuned_mape': [ar_tuned_mape, ma_tuned_mape, arima_tuned_mape, sarima_tuned_mape, arimax_tuned_mape, sarimax_tuned_mape]\n",
    "}\n",
    "\n",
    "# Convertting dictionary into a DataFrame\n",
    "results_df = pd.DataFrame(results_dict)\n",
    "\n",
    "# Display of table\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38d75a9-0579-47c3-bc25-fbc601078bb7",
   "metadata": {},
   "source": [
    "## CONCLUSION\n",
    "- While ARIMAX and SARIMAX have the same error metrics, SARIMAX aligns better with the actual data trends, capturing seasonality and fluctuations effectively.\n",
    "- SARIMAX visually matches the ups and downs of demand trends more closely, reflecting real-world patterns that are critical for actionable and reliable long-term forecasts.\n",
    "- SARIMAX is specifically designed to handle both seasonality and external influences (exogenous variables). This makes it ideal for retail demand forecasting, where periodic variations are significant\n",
    "- Despite slightly higher error metrics, its graphical accuracy ensures that it captures real-world demand trends, making it more reliable for long-term use.The ability to handle seasonal components ensures robustness for retail scenarios with recurring patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37863c78-1d63-43e6-b9ef-7e41949f1a5b",
   "metadata": {},
   "source": [
    "# Multivariate Regression Model Fitting And Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2140b0f9-2a92-4179-a871-18b022204b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['New_Quantity_lag1'] = df['New_Quantity'].shift(1)\n",
    "df['Clicks_lag1'] = df['Clicks'].shift(1)\n",
    "df['Impressions_lag1'] = df['Impressions'].shift(1)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Spliting of data into features and target\n",
    "X = df[['New_Quantity_lag1', 'Clicks_lag1', 'Impressions_lag1', 'mon', 'tue', 'wed', 'thur', 'fri', 'sat', 'sun', 'jan', 'feb', 'march', 'april', \n",
    "           'may', 'june', 'july', 'august', 'sep', 'oct', 'nov', 'dec']]\n",
    "y = df['New_Quantity']\n",
    "train_size = int(len(df) * 0.8)\n",
    "X_train = X[:train_size]\n",
    "X_test = X[train_size:]\n",
    "y_train = y[:train_size]\n",
    "y_test = y[train_size:]\n",
    "initial_model = LinearRegression()\n",
    "initial_model.fit(X_train, y_train)\n",
    "y_pred_initial = initial_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f7ea86-85ac-424b-8cee-654ccfa3b7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MA_mae = mean_absolute_error(y_test, y_pred_initial)\n",
    "MA_rmse = np.sqrt(mean_squared_error(y_test, y_pred_initial))\n",
    "MA_mape = np.mean(np.abs((y_test - y_pred_initial) / y_test)) * 100\n",
    "\n",
    "print(f\"MAE: {MA_mae:.2f}\")\n",
    "print(f\"RMSE: {MA_rmse:.2f}\")\n",
    "print(f\"MAPE: {MA_mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a0f03b-1b52-40c5-bcc2-16b0f486611a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_test_sorted = y_test.reset_index(drop=True)  \n",
    "y_pred_sorted = pd.Series(y_pred_initial, index=y_test_sorted.index)\n",
    "\n",
    "# Plotting Actual vs Predicted\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_test_sorted, label='Actual Sales', color='blue')\n",
    "plt.plot(y_pred_sorted, label='Predicted Sales', color='red')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Sales')\n",
    "plt.title('Multivariate Actual vs Predicted Sales ')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc354d7d-1e38-4aab-8859-80b942086d2e",
   "metadata": {},
   "source": [
    "* RMSE,MAPE and MAE values are the least for this model\n",
    "* Through the Graph we can say that the model is able to understand the data better compared to the other model and is visually appealing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c33236-51d3-47c8-baa3-1f035ed6aab0",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning(With Error Percentage Calculation) And Residual Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcc4b64-1691-429f-866c-548b928707ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200], \n",
    "    'max_depth': [None, 10, 20, 30],  \n",
    "    'min_samples_split': [2, 5, 10],  \n",
    "    'min_samples_leaf': [1, 2, 4],   \n",
    "    'bootstrap': [True, False]        \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "\n",
    "# Fit of GridSearchCV on the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print of best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best Parameters from Grid Search: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e257a3-a1c8-4242-9cc0-5b9d5ab4952f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "MA_tuned_mae = mean_absolute_error(y_test, y_pred)\n",
    "MA_tuned_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "MA_tuned_mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "\n",
    "print(f\"Tuned MAE: {MA_tuned_mae:.2f}\")\n",
    "print(f\"Tuned RMSE: {MA_tuned_rmse:.2f}\")\n",
    "print(f\"Tuned MAPE: {MA_tuned_mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70acb30d-d2cb-4b11-801b-120653621299",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_tuned = best_model.predict(X_test)\n",
    "y_test_sorted = y_test.reset_index(drop=True)\n",
    "y_pred_sorted = pd.Series(y_pred_tuned, index=y_test_sorted.index)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_test_sorted, label='Actual Sales', color='blue')\n",
    "plt.plot(y_pred_sorted, label='Predicted Sales (Tuned)', color='green')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Sales')\n",
    "plt.title('Actual vs Predicted Sales (Tuned Model - Line Graph)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2b3b5d-1e39-415a-875b-8e1a07c20a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation of residuals\n",
    "residuals_tuned = y_test.reset_index(drop=True) - pd.Series(y_pred_tuned)\n",
    "\n",
    "# Plot of residuals as a line graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(residuals_tuned, label='Residuals', color='purple')\n",
    "plt.axhline(0, color='red', linestyle='--', linewidth=1.5) \n",
    "plt.title('Residuals (Tuned Model)')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Residuals')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72aec354-2f55-461c-8c0a-30fa526bdada",
   "metadata": {},
   "source": [
    "# Final Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbbe524-1b7f-487e-9210-6494812fe8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {\n",
    "    'Model_name': ['ar', 'ma', 'arima', 'sarima', 'arimax', 'sarimax', 'multivariate'],\n",
    "    'mae': [ar_mae, ma_mae,arima_mae, sarima_mae, arimax_mae, sarimax_mae, MA_mae],\n",
    "    'rmse': [ar_rmse, ma_rmse, arima_rmse, sarima_rmse, arimax_rmse, sarimax_rmse, MA_rmse],\n",
    "    'mape': [ar_mape, ma_mape, arima_mape, sarima_mape, arimax_mape, sarimax_mape, MA_mape],\n",
    "    'tuned_mae': [ar_tuned_mae, ma_tuned_mae, arima_tuned_mae, sarima_tuned_mae, arimax_tuned_mae, sarimax_tuned_mae, MA_tuned_mae],\n",
    "    'tuned_rmse': [ar_tuned_rmse, ma_tuned_rmse, arima_tuned_rmse, sarima_tuned_rmse, arimax_tuned_rmse, sarimax_tuned_rmse, MA_tuned_rmse],\n",
    "    'tuned_mape': [ar_tuned_mape, ma_tuned_mape, arima_tuned_mape, sarima_tuned_mape, arimax_tuned_mape, sarimax_tuned_mape, MA_tuned_mape]\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results_dict)\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fec0c56-81ba-4e6a-a8f5-4f10843433f8",
   "metadata": {},
   "source": [
    "# CONCLUSION\n",
    "* The effective management of seasonality in data analysis is addressed through the SARIMAX model, specifically utilizing the seasonal_order parameter. This parameter plays a significant role in adapting the model to cyclical fluctuations inherent in the data set.\n",
    "* Although the SARIMAX model does not achieve the lowest values for mean absolute error (MAE), root mean square error (RMSE), or mean absolute percentage error (MAPE), it compensates for this by its adeptness at addressing seasonal variations and integrating external variables. Such capabilities render it particularly beneficial when analyzing data characterized by cyclical behaviors, such as sales or demand fluctuations.\n",
    "* Improvements in forecast accuracy have been observed with the application of a tuned SARIMAX model, wherein parameters have been optimized. This refinement contributes to enhanced forecasting capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cebfd18-402d-4786-b5e6-7a71becf76cd",
   "metadata": {},
   "source": [
    "# FORECASTING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b5e116-6c2d-4548-93a3-cf75e299390b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['New_Quantity']\n",
    "explanatory_vars = ['Impressions', 'Clicks', 'mon', 'tue', 'wed', 'thur', 'fri', 'sat', 'sun', 'jan', 'feb', 'march', 'april', \n",
    "           'may', 'june', 'july', 'august', 'sep', 'oct', 'nov', 'dec']\n",
    "exog = df[explanatory_vars]\n",
    "\n",
    "train_split_index = int(len(df) * 0.8)\n",
    "train_target = target[:train_split_index]\n",
    "test_target = target[train_split_index:]\n",
    "train_exog = exog[:train_split_index]\n",
    "test_exog = exog[train_split_index:]\n",
    "\n",
    "future_days = 60\n",
    "future_dates = pd.date_range(start=df.index[-1] + pd.Timedelta(days=1), periods=future_days, freq='D')\n",
    "future_exog = pd.DataFrame(0, index=future_dates, columns=test_exog.columns)\n",
    "\n",
    "# Combining test data and future data for exogenous variables\n",
    "all_test_exog = pd.concat([test_exog, future_exog])\n",
    "\n",
    "# Building and fitting of SARIMAX model\n",
    "sarimax_model = SARIMAX(train_target, exog=train_exog, order=(0, 1, 1), seasonal_order=(0, 1, 1, 12))\n",
    "sarimax_results = sarimax_model.fit(disp=False)\n",
    "\n",
    "# Forecasting \n",
    "forecast_steps = len(all_test_exog)\n",
    "forecast = sarimax_results.get_forecast(steps=forecast_steps, exog=all_test_exog)\n",
    "forecast_values = forecast.predicted_mean\n",
    "\n",
    "# Plot of actual data and forecast data\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(df.index, target, label='Original Data', linestyle='-', color='yellow', marker='o', linewidth=1)  \n",
    "plt.plot(all_test_exog.index, forecast_values, label='Forecast Data', color='red') \n",
    "plt.title(\"Future Forecast for Next 2 Months\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585c24f6-5cd7-4517-a144-6d70c1db04bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_weekly = target.resample('W').sum()\n",
    "forecast_weekly = forecast_values.resample('W').sum()\n",
    "# plot of forecast weekly basis\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(actual_weekly.index, actual_weekly, label='Original Data', color='blue', marker='o', linestyle='-', linewidth=1)\n",
    "plt.plot(forecast_weekly.index, forecast_weekly, label='Forecasted Data', color='red', marker='o', linestyle='-', linewidth=1)\n",
    "plt.title(\"Forecasted Data (Weekly basis)\", fontsize=14)\n",
    "plt.xlabel(\"Week\", fontsize=12)\n",
    "plt.ylabel(\"Quantity\", fontsize=12)\n",
    "plt.legend(loc='upper left', fontsize=10)\n",
    "plt.grid(alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be5a24b-26b3-4009-854f-867a5c5b2955",
   "metadata": {},
   "source": [
    "# CONCLUSION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddf9b38-0063-4d2a-9d38-35738c7756a7",
   "metadata": {},
   "source": [
    "*The conclusion encompasses four distinct yet interconnected points that highlight the significance of employing the SARIMAX model for demand forecasting in a business context.*\n",
    "\n",
    "* Firstly, the utilization of the SARIMAX model for forecasting demand is noteworthy. This model integrates historical data alongside exogenous variables, such as Impressions, Clicks, and temporal indicators, facilitating a robust predictive framework.\n",
    "* Secondly, the accuracy and reliability of the predictions generated by the SARIMAX model are emphasized. These predictions enable the discernment of future trends and demand patterns, which are essential for informed decision-making.\n",
    "* Furthermore, the application of these forecasts within the business sector is instrumental. Effective management of inventory is achieved, as businesses can maintain optimal stock levels, thereby mitigating the risks associated with overstocking and stockouts.\n",
    "* Lastly, the strategic implications of employing the SARIMAX model for decision-making processes are significant. By harnessing data-driven insights, businesses are better positioned to navigate market fluctuations and enhance the allocation of resources, ultimately fostering a competitive advantage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86111e0-4efd-46a3-b66b-a24eae86ff07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
